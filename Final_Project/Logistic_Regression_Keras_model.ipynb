{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "olive-classic",
   "metadata": {},
   "source": [
    "# Stroke modeling with Logistic Regression and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "italic-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>33.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  \\\n",
       "0   9046       1  67.0             0              1             1   \n",
       "1  51676       0  61.0             0              0             1   \n",
       "2  31112       1  80.0             0              1             1   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  stroke  work_type_Govt_job  \\\n",
       "0               1             228.69  36.6       1                   0   \n",
       "1               0             202.21  33.2       1                   0   \n",
       "2               0             105.92  32.5       1                   0   \n",
       "\n",
       "   work_type_Private  work_type_Self-employed  smoking_status_Unknown  \\\n",
       "0                  1                        0                       0   \n",
       "1                  0                        1                       0   \n",
       "2                  1                        0                       0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data sets\n",
    "\n",
    "stroke_raw_df = pd.read_csv(\"stroke_raw_df.csv\", index_col=0)\n",
    "stroke_norm_df = pd.read_csv(\"stroke_norm_df.csv\", index_col=0)\n",
    "stroke_scaled_df = pd.read_csv(\"stroke_scaled_df.csv\", index_col=0)\n",
    "\n",
    "stroke_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "complicated-raising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801173</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678875</td>\n",
       "      <td>0.271375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234159</td>\n",
       "      <td>0.262701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender       age  hypertension  heart_disease  ever_married  \\\n",
       "0   9046       1  0.736842             0              1             1   \n",
       "1  51676       0  0.631579             0              0             1   \n",
       "2  31112       1  0.964912             0              1             1   \n",
       "\n",
       "   Residence_type  avg_glucose_level       bmi  stroke  work_type_Govt_job  \\\n",
       "0               1           0.801173  0.313507       1                   0   \n",
       "1               0           0.678875  0.271375       1                   0   \n",
       "2               0           0.234159  0.262701       1                   0   \n",
       "\n",
       "   work_type_Private  work_type_Self-employed  smoking_status_Unknown  \\\n",
       "0                  1                        0                       0   \n",
       "1                  0                        1                       0   \n",
       "2                  1                        0                       0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_norm_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "functioning-myanmar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.874738</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.464581</td>\n",
       "      <td>0.819354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.918619</td>\n",
       "      <td>0.342896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>1.686716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.066679</td>\n",
       "      <td>0.244801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender       age  hypertension  heart_disease  ever_married  \\\n",
       "0   9046       1  0.874738             0              1             1   \n",
       "1  51676       0  0.499979             0              0             1   \n",
       "2  31112       1  1.686716             0              1             1   \n",
       "\n",
       "   Residence_type  avg_glucose_level       bmi  stroke  work_type_Govt_job  \\\n",
       "0               1           2.464581  0.819354       1                   0   \n",
       "1               0           1.918619  0.342896       1                   0   \n",
       "2               0          -0.066679  0.244801       1                   0   \n",
       "\n",
       "   work_type_Private  work_type_Self-employed  smoking_status_Unknown  \\\n",
       "0                  1                        0                       0   \n",
       "1                  0                        1                       0   \n",
       "2                  1                        0                       0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_scaled_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-tender",
   "metadata": {},
   "source": [
    "### Create Train and Test data sets for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "classical-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Raw data\n",
    "\n",
    "X_raw = stroke_raw_df.drop(['id', 'stroke'], axis=1)\n",
    "y_raw = stroke_raw_df['stroke']\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X_raw, y_raw, test_size = 0.25, \n",
    "                                                                    random_state = 42, stratify = y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "former-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normed data\n",
    "\n",
    "X_norm = stroke_norm_df.drop(['id', 'stroke'], axis=1)\n",
    "y_norm = stroke_norm_df['stroke']\n",
    "\n",
    "X_norm_train, X_norm_test, y_norm_train, y_norm_test = train_test_split(X_norm, y_norm, test_size = 0.25, \n",
    "                                                                    random_state = 42, stratify = y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "casual-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled data\n",
    "\n",
    "X_scaled = stroke_scaled_df.drop(['id', 'stroke'], axis=1)\n",
    "y_scaled = stroke_scaled_df['stroke']\n",
    "\n",
    "X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X_scaled, y_scaled, test_size = 0.25, \n",
    "                                                                    random_state = 42, stratify = y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-spirituality",
   "metadata": {},
   "source": [
    "### Create new data set with random over sampling and cluster centroid under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "complicated-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of stroke patients (minority class):  6.61\n"
     ]
    }
   ],
   "source": [
    "minority_class_percent = (len(stroke_raw_df[stroke_raw_df['stroke'] == 1])/len(stroke_raw_df))*100\n",
    "print(\"Percentage of stroke patients (minority class): \", round(minority_class_percent, 2))\n",
    "\n",
    "#minority class 6.6% of the all the data, heavily imbalanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-corps",
   "metadata": {},
   "source": [
    "#### Set up RandomOverSampler and ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "genuine-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2618, 1: 185})\n"
     ]
    }
   ],
   "source": [
    "#Resample the training data with RandomOversampler and Clustered Centroids\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "# define over/under sampling strategies\n",
    "ros = RandomOverSampler(sampling_strategy=.15, random_state = 42)\n",
    "cc = ClusterCentroids(sampling_strategy=.75, random_state=42)\n",
    "\n",
    "#orignal number of each target class\n",
    "print(Counter(y_raw_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-point",
   "metadata": {},
   "source": [
    "**Raw data, over and under sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "known-horror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2618, 1: 392})\n",
      "Counter({0: 522, 1: 392})\n"
     ]
    }
   ],
   "source": [
    "# apply over sampling strategy on original data\n",
    "X_r_train_resampled, y_r_train_resampled = ros.fit_resample(X_raw_train, y_raw_train)\n",
    "print(Counter(y_r_train_resampled))\n",
    "\n",
    "#apply under sampling strategy on oversampled data\n",
    "X_r_train_resampled, y_r_train_resampled = cc.fit_resample(X_r_train_resampled, y_r_train_resampled)\n",
    "print(Counter(y_r_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-trinity",
   "metadata": {},
   "source": [
    "**Normed data, over and under sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "educational-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2618, 1: 392})\n",
      "Counter({0: 522, 1: 392})\n"
     ]
    }
   ],
   "source": [
    "# apply over sampling strategy on original data\n",
    "X_n_train_resampled, y_n_train_resampled = ros.fit_resample(X_norm_train, y_norm_train)\n",
    "print(Counter(y_n_train_resampled))\n",
    "\n",
    "#apply under sampling strategy on oversampled data\n",
    "X_n_train_resampled, y_n_train_resampled = cc.fit_resample(X_n_train_resampled, y_n_train_resampled)\n",
    "print(Counter(y_n_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-focus",
   "metadata": {},
   "source": [
    "**Scaled data, over and under sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bibliographic-muslim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2618, 1: 392})\n",
      "Counter({0: 522, 1: 392})\n"
     ]
    }
   ],
   "source": [
    "# apply over sampling strategy on original data\n",
    "X_s_train_resampled, y_s_train_resampled = ros.fit_resample(X_scaled_train, y_scaled_train)\n",
    "print(Counter(y_s_train_resampled))\n",
    "\n",
    "#apply under sampling strategy on oversampled data\n",
    "X_s_train_resampled, y_s_train_resampled = cc.fit_resample(X_s_train_resampled, y_s_train_resampled)\n",
    "print(Counter(y_s_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-taylor",
   "metadata": {},
   "source": [
    "### Create new data set with SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "sweet-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "#create new minority class data points\n",
    "#clean up majority class data points\n",
    "# may lead to more false positive, but fewer false negatives\n",
    "\n",
    "smote = SMOTEENN(random_state=42) #, enn=EditedNearestNeighbours(sampling_strategy='majority'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-database",
   "metadata": {},
   "source": [
    "**Raw data, SMOTEEN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "dying-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2410, 0: 1800})\n"
     ]
    }
   ],
   "source": [
    "# apply SMOTEEN on original data\n",
    "X_r_train_smoteen, y_r_train_smoteen = smote.fit_resample(X_raw_train, y_raw_train)\n",
    "print(Counter(y_r_train_smoteen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-conservation",
   "metadata": {},
   "source": [
    "**Normalized data, SMOTEEN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "british-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2256, 0: 1985})\n"
     ]
    }
   ],
   "source": [
    "# apply SMOTEEN on normalized data\n",
    "X_n_train_smoteen, y_n_train_smoteen = smote.fit_resample(X_norm_train, y_norm_train)\n",
    "print(Counter(y_n_train_smoteen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-sheriff",
   "metadata": {},
   "source": [
    "**Scaled data, SMOTEEN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "southeast-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2489, 0: 2023})\n"
     ]
    }
   ],
   "source": [
    "# apply SMOTEEN on scaled data\n",
    "X_s_train_smoteen, y_s_train_smoteen = smote.fit_resample(X_scaled_train, y_scaled_train)\n",
    "print(Counter(y_s_train_smoteen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-circular",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "british-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 873, 1: 62})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "\n",
    "def run_LR(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Automate run and performance of Logistic Regression Models\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Train data balanced accuracy: \", balanced_accuracy_score(y_train, y_train_pred))\n",
    "    print(\"Test data balanced accuracy: \", balanced_accuracy_score(y_test, y_pred))\n",
    "    \n",
    "\n",
    "print(Counter(y_norm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-interference",
   "metadata": {},
   "source": [
    "#### Normed data, no resampling strategy\n",
    "\n",
    "Poor performance - no stroke victims identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "killing-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873   0]\n",
      " [ 62   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       873\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.93       935\n",
      "   macro avg       0.47      0.50      0.48       935\n",
      "weighted avg       0.87      0.93      0.90       935\n",
      "\n",
      "Train data balanced accuracy:  0.5027027027027027\n",
      "Test data balanced accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_norm_train, y_norm_train, X_norm_test, y_norm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-institute",
   "metadata": {},
   "source": [
    "#### Normed data, resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "realistic-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[640 233]\n",
      " [ 24  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83       873\n",
      "           1       0.14      0.61      0.23        62\n",
      "\n",
      "    accuracy                           0.73       935\n",
      "   macro avg       0.55      0.67      0.53       935\n",
      "weighted avg       0.91      0.73      0.79       935\n",
      "\n",
      "Train data balanced accuracy:  0.6969074986316366\n",
      "Test data balanced accuracy:  0.6730037320326645\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_n_train_resampled, y_n_train_resampled, X_norm_test, y_norm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-playing",
   "metadata": {},
   "source": [
    "#### Normed data, SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "applied-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[599 274]\n",
      " [ 13  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81       873\n",
      "           1       0.15      0.79      0.25        62\n",
      "\n",
      "    accuracy                           0.69       935\n",
      "   macro avg       0.57      0.74      0.53       935\n",
      "weighted avg       0.92      0.69      0.77       935\n",
      "\n",
      "Train data balanced accuracy:  0.8154661736070171\n",
      "Test data balanced accuracy:  0.7382311643202897\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_n_train_smoteen, y_n_train_smoteen, X_norm_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-activation",
   "metadata": {},
   "source": [
    "#### Scaled data, no resampling strategy\n",
    "\n",
    "Poor performance - no stroke victims identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "unusual-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873   0]\n",
      " [ 62   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       873\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.93       935\n",
      "   macro avg       0.47      0.50      0.48       935\n",
      "weighted avg       0.87      0.93      0.90       935\n",
      "\n",
      "Train data balanced accuracy:  0.5027027027027027\n",
      "Test data balanced accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_scaled_train, y_scaled_train, X_scaled_test, y_scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-bhutan",
   "metadata": {},
   "source": [
    "#### Scaled data, resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bored-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[628 245]\n",
      " [ 22  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.82       873\n",
      "           1       0.14      0.65      0.23        62\n",
      "\n",
      "    accuracy                           0.71       935\n",
      "   macro avg       0.55      0.68      0.53       935\n",
      "weighted avg       0.91      0.71      0.79       935\n",
      "\n",
      "Train data balanced accuracy:  0.7393365392133866\n",
      "Test data balanced accuracy:  0.682259912057052\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_s_train_resampled, y_s_train_resampled, X_scaled_test, y_scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-memorial",
   "metadata": {},
   "source": [
    "#### Scaled data, SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "supreme-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[631 242]\n",
      " [ 14  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83       873\n",
      "           1       0.17      0.77      0.27        62\n",
      "\n",
      "    accuracy                           0.73       935\n",
      "   macro avg       0.57      0.75      0.55       935\n",
      "weighted avg       0.92      0.73      0.79       935\n",
      "\n",
      "Train data balanced accuracy:  0.8467888467040445\n",
      "Test data balanced accuracy:  0.7484942541477293\n"
     ]
    }
   ],
   "source": [
    "run_LR(X_s_train_smoteen, y_s_train_smoteen, X_scaled_test, y_scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-control",
   "metadata": {},
   "source": [
    "#### Run Logistic Regression using Lasso results on normed, SMOTEEN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "italic-jaguar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[593 280]\n",
      " [ 12  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80       873\n",
      "           1       0.15      0.81      0.26        62\n",
      "\n",
      "    accuracy                           0.69       935\n",
      "   macro avg       0.57      0.74      0.53       935\n",
      "weighted avg       0.93      0.69      0.77       935\n",
      "\n",
      "Train data balanced accuracy:  0.8006652285760223\n",
      "Test data balanced accuracy:  0.7428592543324835\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = ['gender', 'bmi', 'work_type_Govt_job', 'work_type_Self-employed', 'smoking_status_Unknown',\n",
    "                    'smoking_status_formerly smoked', 'smoking_status_smokes']\n",
    "X_lasso_train = X_n_train_smoteen.drop(features_to_drop, axis=1)\n",
    "X_lasso_test = X_norm_test.drop(features_to_drop, axis=1)\n",
    "\n",
    "run_LR(X_lasso_train, y_n_train_smoteen, X_lasso_test, y_norm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-rabbit",
   "metadata": {},
   "source": [
    "##### SMOTEEN resampling strategy outperformed the over sampling, clustered centroid strategy.\n",
    "\n",
    "Normed and scaled data both performed somewhat similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-picnic",
   "metadata": {},
   "source": [
    "### GridSearch to tune Logistic Regression model with normed SMOTEEN data\n",
    "\n",
    "Goal to drive the false negative rate down (at the expense of the false postive rate).   Using recall as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "magnetic-pressure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.85816323        nan 0.85018879        nan 0.85550639\n",
      "        nan 0.85018486        nan 0.84974238]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(max_iter=5000, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "\n",
    "#logistic regression model\n",
    "best_lr_model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "\n",
    "#tune parameters\n",
    "params_lr = {'C': [.01, .1, 1, 10, 100],\n",
    "             'penalty': ['l1', 'l2']\n",
    "            }\n",
    "\n",
    "grid_lr = GridSearchCV(estimator=best_lr_model, param_grid=params_lr, scoring='recall',\n",
    "                      cv=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "grid_lr.fit(X_n_train_smoteen, y_n_train_smoteen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "concrete-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      " {'C': 0.01, 'penalty': 'l2'}\n",
      "Best Recall Score: \n",
      " 0.8581632251720747\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_lr.best_params_\n",
    "best_CV_score = grid_lr.best_score_\n",
    "print(\"Best Parameters: \\n\", best_params)\n",
    "print(\"Best Recall Score: \\n\", best_CV_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "opened-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[561 312]\n",
      " [ 10  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.78       873\n",
      "           1       0.14      0.84      0.24        62\n",
      "\n",
      "    accuracy                           0.66       935\n",
      "   macro avg       0.56      0.74      0.51       935\n",
      "weighted avg       0.93      0.66      0.74       935\n",
      "\n",
      "Train data balanced accuracy:  0.7911032656269539\n",
      "Test data balanced accuracy:  0.7406606806340761\n",
      "Test recall score:  0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "# name best model\n",
    "lr_best_model = grid_lr.best_estimator_\n",
    "# use model to predict on test data (held back)\n",
    "y_pred = lr_best_model.predict(X_norm_test)\n",
    "\n",
    "print(confusion_matrix(y_norm_test, y_pred))\n",
    "print(classification_report(y_norm_test, y_pred))\n",
    "y_train_pred = lr_best_model.predict(X_n_train_smoteen)\n",
    "print(\"Train data balanced accuracy: \", balanced_accuracy_score(y_n_train_smoteen, y_train_pred))\n",
    "print(\"Test data balanced accuracy: \", balanced_accuracy_score(y_norm_test, y_pred))\n",
    "print(\"Test recall score: \", recall_score(y_norm_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-break",
   "metadata": {},
   "source": [
    "##### Parameter tuned logistic regression model is slightly overfitted, but performs well for recall in the test sample.\n",
    "\n",
    "Looking at the original normed data and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "random-powell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2220 1271]\n",
      " [  44  203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      3491\n",
      "           1       0.14      0.82      0.24       247\n",
      "\n",
      "    accuracy                           0.65      3738\n",
      "   macro avg       0.56      0.73      0.50      3738\n",
      "weighted avg       0.92      0.65      0.74      3738\n",
      "\n",
      "Data balanced accuracy:  0.7288916438685016\n",
      "Test recall score:  0.8218623481781376\n"
     ]
    }
   ],
   "source": [
    "# Going back to original normed data: how does the model perform?\n",
    "model_y = lr_best_model.predict(X_norm)\n",
    "print(confusion_matrix(y_norm, model_y))\n",
    "print(classification_report(y_norm, model_y))\n",
    "print(\"Data balanced accuracy: \", balanced_accuracy_score(y_norm, model_y))\n",
    "print(\"Test recall score: \", recall_score(y_norm, model_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "amazing-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18092877,  1.92034162,  0.23838581,  0.2714037 , -0.00416373,\n",
       "        -0.06605773,  0.66203399, -0.05068571, -0.39502637, -0.07505169,\n",
       "         0.06365918, -0.05889108,  0.09041746, -0.26327729, -0.16072952]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-phoenix",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "given-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-harris",
   "metadata": {},
   "source": [
    "#### Binary Keras model with normalized, SMOTEEN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "flush-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 - 1s - loss: 0.5277 - binary_accuracy: 0.7268 - val_loss: 0.5147 - val_binary_accuracy: 0.7714\n",
      "Epoch 2/50\n",
      "93/93 - 0s - loss: 0.3816 - binary_accuracy: 0.8241 - val_loss: 0.5635 - val_binary_accuracy: 0.7596\n",
      "Epoch 3/50\n",
      "93/93 - 0s - loss: 0.3500 - binary_accuracy: 0.8443 - val_loss: 0.6560 - val_binary_accuracy: 0.6999\n",
      "Epoch 4/50\n",
      "93/93 - 0s - loss: 0.3235 - binary_accuracy: 0.8629 - val_loss: 0.6051 - val_binary_accuracy: 0.7321\n",
      "Epoch 5/50\n",
      "93/93 - 0s - loss: 0.3111 - binary_accuracy: 0.8649 - val_loss: 0.3818 - val_binary_accuracy: 0.8515\n",
      "Epoch 6/50\n",
      "93/93 - 0s - loss: 0.2971 - binary_accuracy: 0.8780 - val_loss: 0.3969 - val_binary_accuracy: 0.8397\n",
      "Epoch 7/50\n",
      "93/93 - 0s - loss: 0.2895 - binary_accuracy: 0.8787 - val_loss: 0.5747 - val_binary_accuracy: 0.7549\n",
      "Epoch 8/50\n",
      "93/93 - 0s - loss: 0.2764 - binary_accuracy: 0.8841 - val_loss: 0.5161 - val_binary_accuracy: 0.7824\n",
      "Epoch 9/50\n",
      "93/93 - 0s - loss: 0.2724 - binary_accuracy: 0.8827 - val_loss: 0.3385 - val_binary_accuracy: 0.8523\n",
      "Epoch 10/50\n",
      "93/93 - 0s - loss: 0.2598 - binary_accuracy: 0.8915 - val_loss: 0.4604 - val_binary_accuracy: 0.8036\n",
      "Epoch 11/50\n",
      "93/93 - 0s - loss: 0.2520 - binary_accuracy: 0.8939 - val_loss: 0.3838 - val_binary_accuracy: 0.8437\n",
      "Epoch 12/50\n",
      "93/93 - 0s - loss: 0.2453 - binary_accuracy: 0.8982 - val_loss: 0.2901 - val_binary_accuracy: 0.8892\n",
      "Epoch 13/50\n",
      "93/93 - 0s - loss: 0.2435 - binary_accuracy: 0.8935 - val_loss: 0.5324 - val_binary_accuracy: 0.7675\n",
      "Epoch 14/50\n",
      "93/93 - 0s - loss: 0.2309 - binary_accuracy: 0.8956 - val_loss: 0.4651 - val_binary_accuracy: 0.8068\n",
      "Epoch 15/50\n",
      "93/93 - 0s - loss: 0.2326 - binary_accuracy: 0.8982 - val_loss: 0.5164 - val_binary_accuracy: 0.7753\n",
      "Epoch 16/50\n",
      "93/93 - 0s - loss: 0.2225 - binary_accuracy: 0.9060 - val_loss: 0.4473 - val_binary_accuracy: 0.8162\n",
      "Epoch 17/50\n",
      "93/93 - 0s - loss: 0.2155 - binary_accuracy: 0.9121 - val_loss: 0.3325 - val_binary_accuracy: 0.8696\n",
      "Epoch 18/50\n",
      "93/93 - 0s - loss: 0.2124 - binary_accuracy: 0.9144 - val_loss: 0.4094 - val_binary_accuracy: 0.8327\n",
      "Epoch 19/50\n",
      "93/93 - 0s - loss: 0.2118 - binary_accuracy: 0.9040 - val_loss: 0.4016 - val_binary_accuracy: 0.8217\n",
      "Epoch 20/50\n",
      "93/93 - 0s - loss: 0.2044 - binary_accuracy: 0.9158 - val_loss: 0.3403 - val_binary_accuracy: 0.8539\n",
      "Epoch 21/50\n",
      "93/93 - 0s - loss: 0.2103 - binary_accuracy: 0.9158 - val_loss: 0.4102 - val_binary_accuracy: 0.8240\n",
      "Epoch 22/50\n",
      "93/93 - 0s - loss: 0.2010 - binary_accuracy: 0.9148 - val_loss: 0.3371 - val_binary_accuracy: 0.8712\n",
      "Epoch 23/50\n",
      "93/93 - 0s - loss: 0.1991 - binary_accuracy: 0.9137 - val_loss: 0.2536 - val_binary_accuracy: 0.9002\n",
      "Epoch 24/50\n",
      "93/93 - 0s - loss: 0.1979 - binary_accuracy: 0.9164 - val_loss: 0.3749 - val_binary_accuracy: 0.8437\n",
      "Epoch 25/50\n",
      "93/93 - 0s - loss: 0.1937 - binary_accuracy: 0.9212 - val_loss: 0.4512 - val_binary_accuracy: 0.8020\n",
      "Epoch 26/50\n",
      "93/93 - 0s - loss: 0.1891 - binary_accuracy: 0.9232 - val_loss: 0.3461 - val_binary_accuracy: 0.8610\n",
      "Epoch 27/50\n",
      "93/93 - 0s - loss: 0.1909 - binary_accuracy: 0.9222 - val_loss: 0.3068 - val_binary_accuracy: 0.8767\n",
      "Epoch 28/50\n",
      "93/93 - 0s - loss: 0.1783 - binary_accuracy: 0.9279 - val_loss: 0.4661 - val_binary_accuracy: 0.8060\n",
      "Epoch 29/50\n",
      "93/93 - 0s - loss: 0.1805 - binary_accuracy: 0.9252 - val_loss: 0.3611 - val_binary_accuracy: 0.8610\n",
      "Epoch 30/50\n",
      "93/93 - 0s - loss: 0.1742 - binary_accuracy: 0.9276 - val_loss: 0.3583 - val_binary_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "93/93 - 0s - loss: 0.1741 - binary_accuracy: 0.9249 - val_loss: 0.2740 - val_binary_accuracy: 0.8955\n",
      "Epoch 32/50\n",
      "93/93 - 0s - loss: 0.1700 - binary_accuracy: 0.9292 - val_loss: 0.3064 - val_binary_accuracy: 0.8680\n",
      "Epoch 33/50\n",
      "93/93 - 0s - loss: 0.1686 - binary_accuracy: 0.9286 - val_loss: 0.3665 - val_binary_accuracy: 0.8594\n",
      "Epoch 34/50\n",
      "93/93 - 0s - loss: 0.1646 - binary_accuracy: 0.9326 - val_loss: 0.4054 - val_binary_accuracy: 0.8366\n",
      "Epoch 35/50\n",
      "93/93 - 0s - loss: 0.1614 - binary_accuracy: 0.9319 - val_loss: 0.2573 - val_binary_accuracy: 0.9065\n",
      "Epoch 36/50\n",
      "93/93 - 0s - loss: 0.1607 - binary_accuracy: 0.9336 - val_loss: 0.3527 - val_binary_accuracy: 0.8570\n",
      "Epoch 37/50\n",
      "93/93 - 1s - loss: 0.1591 - binary_accuracy: 0.9306 - val_loss: 0.4773 - val_binary_accuracy: 0.8020\n",
      "Epoch 38/50\n",
      "93/93 - 0s - loss: 0.1607 - binary_accuracy: 0.9333 - val_loss: 0.3601 - val_binary_accuracy: 0.8625\n",
      "Epoch 39/50\n",
      "93/93 - 0s - loss: 0.1548 - binary_accuracy: 0.9333 - val_loss: 0.4415 - val_binary_accuracy: 0.8138\n",
      "Epoch 40/50\n",
      "93/93 - 0s - loss: 0.1545 - binary_accuracy: 0.9343 - val_loss: 0.2246 - val_binary_accuracy: 0.9301\n",
      "Epoch 41/50\n",
      "93/93 - 0s - loss: 0.1504 - binary_accuracy: 0.9390 - val_loss: 0.2765 - val_binary_accuracy: 0.8955\n",
      "Epoch 42/50\n",
      "93/93 - 0s - loss: 0.1525 - binary_accuracy: 0.9353 - val_loss: 0.2895 - val_binary_accuracy: 0.8971\n",
      "Epoch 43/50\n",
      "93/93 - 0s - loss: 0.1473 - binary_accuracy: 0.9373 - val_loss: 0.2184 - val_binary_accuracy: 0.9387\n",
      "Epoch 44/50\n",
      "93/93 - 0s - loss: 0.1480 - binary_accuracy: 0.9387 - val_loss: 0.3411 - val_binary_accuracy: 0.8751\n",
      "Epoch 45/50\n",
      "93/93 - 0s - loss: 0.1412 - binary_accuracy: 0.9414 - val_loss: 0.2680 - val_binary_accuracy: 0.8963\n",
      "Epoch 46/50\n",
      "93/93 - 0s - loss: 0.1478 - binary_accuracy: 0.9400 - val_loss: 0.3132 - val_binary_accuracy: 0.8672\n",
      "Epoch 47/50\n",
      "93/93 - 0s - loss: 0.1398 - binary_accuracy: 0.9434 - val_loss: 0.3715 - val_binary_accuracy: 0.8539\n",
      "Epoch 48/50\n",
      "93/93 - 0s - loss: 0.1422 - binary_accuracy: 0.9410 - val_loss: 0.4185 - val_binary_accuracy: 0.8256\n",
      "Epoch 49/50\n",
      "93/93 - 0s - loss: 0.1426 - binary_accuracy: 0.9390 - val_loss: 0.3322 - val_binary_accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d9306d0>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features\n",
    "n_cols = X_n_train_smoteen.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2, monitor='loss')\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(X_n_train_smoteen, y_n_train_smoteen, callbacks=[early_stopping_monitor], \n",
    "          epochs=50, verbose=2, validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "public-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7135 - binary_accuracy: 0.7818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.713529646396637, 0.7818182110786438]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_norm_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-floor",
   "metadata": {},
   "source": [
    "##### Evaluate on held back test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "magnetic-congo",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[709 164]\n",
      " [ 40  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87       873\n",
      "           1       0.12      0.35      0.18        62\n",
      "\n",
      "    accuracy                           0.78       935\n",
      "   macro avg       0.53      0.58      0.53       935\n",
      "weighted avg       0.89      0.78      0.83       935\n",
      "\n",
      "Test data balanced accuracy:  0.583490374311791\n",
      "Test recall score:  0.3548387096774194\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_norm_test)\n",
    "y_pred = np.round(y_pred)\n",
    "print(confusion_matrix(y_norm_test, y_pred))\n",
    "print(classification_report(y_norm_test, y_pred))\n",
    "\n",
    "print(\"Test data balanced accuracy: \", balanced_accuracy_score(y_norm_test, y_pred))\n",
    "print(\"Test recall score: \", recall_score(y_norm_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-wireless",
   "metadata": {},
   "source": [
    "#####  The binary keras model on normed, SMOTEEN data performs poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-passenger",
   "metadata": {},
   "source": [
    "### Keras model using normalized data, balanced class weighting, no resampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "alternative-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53533231, 7.57567568])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated weights to use\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate the weights for each class so that we can balance the data\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            [0, 1],\n",
    "                                            np.array(y_norm_train))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "comparable-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 - 1s - loss: 0.6722 - accuracy: 0.4307 - val_loss: 0.5803 - val_accuracy: 0.7812\n",
      "Epoch 2/50\n",
      "62/62 - 0s - loss: 0.6126 - accuracy: 0.6325 - val_loss: 0.5815 - val_accuracy: 0.7087\n",
      "Epoch 3/50\n",
      "62/62 - 0s - loss: 0.5605 - accuracy: 0.6876 - val_loss: 0.5437 - val_accuracy: 0.7170\n",
      "Epoch 4/50\n",
      "62/62 - 0s - loss: 0.5282 - accuracy: 0.7181 - val_loss: 0.6262 - val_accuracy: 0.6576\n",
      "Epoch 5/50\n",
      "62/62 - 0s - loss: 0.5195 - accuracy: 0.7166 - val_loss: 0.6315 - val_accuracy: 0.6599\n",
      "Epoch 6/50\n",
      "62/62 - 0s - loss: 0.5049 - accuracy: 0.7100 - val_loss: 0.4298 - val_accuracy: 0.7860\n",
      "Epoch 7/50\n",
      "62/62 - 0s - loss: 0.4980 - accuracy: 0.7350 - val_loss: 0.5380 - val_accuracy: 0.7015\n",
      "Epoch 8/50\n",
      "62/62 - 0s - loss: 0.4869 - accuracy: 0.7212 - val_loss: 0.4889 - val_accuracy: 0.7360\n",
      "Epoch 9/50\n",
      "62/62 - 0s - loss: 0.4746 - accuracy: 0.7360 - val_loss: 0.4666 - val_accuracy: 0.7527\n",
      "Epoch 10/50\n",
      "62/62 - 0s - loss: 0.4706 - accuracy: 0.7365 - val_loss: 0.5804 - val_accuracy: 0.6908\n",
      "Epoch 11/50\n",
      "62/62 - 0s - loss: 0.4665 - accuracy: 0.7390 - val_loss: 0.5034 - val_accuracy: 0.7313\n",
      "Epoch 12/50\n",
      "62/62 - 0s - loss: 0.4630 - accuracy: 0.7406 - val_loss: 0.4693 - val_accuracy: 0.7503\n",
      "Epoch 13/50\n",
      "62/62 - 0s - loss: 0.4471 - accuracy: 0.7431 - val_loss: 0.4524 - val_accuracy: 0.7622\n",
      "Epoch 14/50\n",
      "62/62 - 0s - loss: 0.4447 - accuracy: 0.7380 - val_loss: 0.4534 - val_accuracy: 0.7562\n",
      "Epoch 15/50\n",
      "62/62 - 0s - loss: 0.4367 - accuracy: 0.7411 - val_loss: 0.5994 - val_accuracy: 0.6694\n",
      "Epoch 16/50\n",
      "62/62 - 0s - loss: 0.4319 - accuracy: 0.7421 - val_loss: 0.5188 - val_accuracy: 0.7289\n",
      "Epoch 17/50\n",
      "62/62 - 0s - loss: 0.4261 - accuracy: 0.7503 - val_loss: 0.6007 - val_accuracy: 0.6825\n",
      "Epoch 18/50\n",
      "62/62 - 0s - loss: 0.4205 - accuracy: 0.7457 - val_loss: 0.4535 - val_accuracy: 0.7610\n",
      "Epoch 19/50\n",
      "62/62 - 0s - loss: 0.4294 - accuracy: 0.7523 - val_loss: 0.6321 - val_accuracy: 0.6564\n",
      "Epoch 20/50\n",
      "62/62 - 0s - loss: 0.4182 - accuracy: 0.7620 - val_loss: 0.7332 - val_accuracy: 0.5886\n",
      "Epoch 21/50\n",
      "62/62 - 0s - loss: 0.4215 - accuracy: 0.7334 - val_loss: 0.5079 - val_accuracy: 0.7229\n",
      "Epoch 22/50\n",
      "62/62 - 0s - loss: 0.4077 - accuracy: 0.7406 - val_loss: 0.5255 - val_accuracy: 0.7194\n",
      "Epoch 23/50\n",
      "62/62 - 0s - loss: 0.3988 - accuracy: 0.7518 - val_loss: 0.5754 - val_accuracy: 0.6920\n",
      "Epoch 24/50\n",
      "62/62 - 0s - loss: 0.3934 - accuracy: 0.7691 - val_loss: 0.5620 - val_accuracy: 0.7027\n",
      "Epoch 25/50\n",
      "62/62 - 0s - loss: 0.3863 - accuracy: 0.7508 - val_loss: 0.4976 - val_accuracy: 0.7432\n",
      "Epoch 26/50\n",
      "62/62 - 0s - loss: 0.3907 - accuracy: 0.7650 - val_loss: 0.4965 - val_accuracy: 0.7372\n",
      "Epoch 27/50\n",
      "62/62 - 0s - loss: 0.3811 - accuracy: 0.7691 - val_loss: 0.4929 - val_accuracy: 0.7527\n",
      "Epoch 28/50\n",
      "62/62 - 0s - loss: 0.3792 - accuracy: 0.7569 - val_loss: 0.5094 - val_accuracy: 0.7455\n",
      "Epoch 29/50\n",
      "62/62 - 0s - loss: 0.3755 - accuracy: 0.7752 - val_loss: 0.6073 - val_accuracy: 0.6718\n",
      "Epoch 30/50\n",
      "62/62 - 0s - loss: 0.3717 - accuracy: 0.7554 - val_loss: 0.6080 - val_accuracy: 0.6813\n",
      "Epoch 31/50\n",
      "62/62 - 0s - loss: 0.3647 - accuracy: 0.7696 - val_loss: 0.4941 - val_accuracy: 0.7515\n",
      "Epoch 32/50\n",
      "62/62 - 0s - loss: 0.3609 - accuracy: 0.7824 - val_loss: 0.5429 - val_accuracy: 0.7301\n",
      "Epoch 33/50\n",
      "62/62 - 0s - loss: 0.3586 - accuracy: 0.7661 - val_loss: 0.5306 - val_accuracy: 0.7301\n",
      "Epoch 34/50\n",
      "62/62 - 0s - loss: 0.3571 - accuracy: 0.7747 - val_loss: 0.5519 - val_accuracy: 0.7218\n",
      "Epoch 35/50\n",
      "62/62 - 0s - loss: 0.3500 - accuracy: 0.7931 - val_loss: 0.5642 - val_accuracy: 0.7194\n",
      "Epoch 36/50\n",
      "62/62 - 0s - loss: 0.3547 - accuracy: 0.7737 - val_loss: 0.5791 - val_accuracy: 0.7063\n",
      "Epoch 37/50\n",
      "62/62 - 0s - loss: 0.3424 - accuracy: 0.7870 - val_loss: 0.4905 - val_accuracy: 0.7705\n",
      "Epoch 38/50\n",
      "62/62 - 0s - loss: 0.3455 - accuracy: 0.7788 - val_loss: 0.4760 - val_accuracy: 0.7765\n",
      "Epoch 39/50\n",
      "62/62 - 0s - loss: 0.3475 - accuracy: 0.7844 - val_loss: 0.5694 - val_accuracy: 0.7063\n",
      "Epoch 40/50\n",
      "62/62 - 0s - loss: 0.3373 - accuracy: 0.8033 - val_loss: 0.5790 - val_accuracy: 0.7099\n",
      "Epoch 41/50\n",
      "62/62 - 0s - loss: 0.3427 - accuracy: 0.7676 - val_loss: 0.5151 - val_accuracy: 0.7455\n",
      "Epoch 42/50\n",
      "62/62 - 0s - loss: 0.3424 - accuracy: 0.7931 - val_loss: 0.6040 - val_accuracy: 0.7015\n",
      "Epoch 43/50\n",
      "62/62 - 0s - loss: 0.3302 - accuracy: 0.7987 - val_loss: 0.5659 - val_accuracy: 0.7277\n",
      "Epoch 44/50\n",
      "62/62 - 0s - loss: 0.3333 - accuracy: 0.7915 - val_loss: 0.5549 - val_accuracy: 0.7372\n",
      "Epoch 45/50\n",
      "62/62 - 0s - loss: 0.3253 - accuracy: 0.8043 - val_loss: 0.5595 - val_accuracy: 0.7313\n",
      "Epoch 46/50\n",
      "62/62 - 0s - loss: 0.3299 - accuracy: 0.7839 - val_loss: 0.5243 - val_accuracy: 0.7658\n",
      "Epoch 47/50\n",
      "62/62 - 0s - loss: 0.3304 - accuracy: 0.7824 - val_loss: 0.5709 - val_accuracy: 0.7206\n",
      "Epoch 48/50\n",
      "62/62 - 0s - loss: 0.3192 - accuracy: 0.8078 - val_loss: 0.5606 - val_accuracy: 0.7408\n",
      "Epoch 49/50\n",
      "62/62 - 0s - loss: 0.3151 - accuracy: 0.7992 - val_loss: 0.5842 - val_accuracy: 0.7194\n",
      "Epoch 50/50\n",
      "62/62 - 0s - loss: 0.3123 - accuracy: 0.7997 - val_loss: 0.5357 - val_accuracy: 0.7717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14da78f10>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using normalized training data\n",
    "\n",
    "weights = {0:.54, 1:7.58}\n",
    "\n",
    "n_cols = X_norm_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3, monitor='loss')\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "model.fit(X_norm_train, y_norm_train, callbacks=[early_stopping_monitor], \n",
    "          epochs=50, verbose=2, class_weight=weights, validation_split=.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "leading-grill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 596us/step - loss: 0.5287 - accuracy: 0.7807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.528740406036377, 0.7807486653327942]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_norm_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "vanilla-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[702 171]\n",
      " [ 34  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87       873\n",
      "           1       0.14      0.45      0.21        62\n",
      "\n",
      "    accuracy                           0.78       935\n",
      "   macro avg       0.55      0.63      0.54       935\n",
      "weighted avg       0.90      0.78      0.83       935\n",
      "\n",
      "Test data balanced accuracy:  0.6278683072830064\n",
      "Test recall score:  0.45161290322580644\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_norm_test)\n",
    "y_pred = np.round(y_pred)\n",
    "print(confusion_matrix(y_norm_test, y_pred))\n",
    "print(classification_report(y_norm_test, y_pred))\n",
    "\n",
    "print(\"Test data balanced accuracy: \", balanced_accuracy_score(y_norm_test, y_pred))\n",
    "print(\"Test recall score: \", recall_score(y_norm_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-secretary",
   "metadata": {},
   "source": [
    "##### This model performs slightly better, but both significantly under perform logistic regression.\n",
    "\n",
    "Maybe with enough time and effort, a neural network might perform as well as or better than a different machine learning model.  With other ML models available, it seems better to spend time to tune those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
